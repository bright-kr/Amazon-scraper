# Amazon Scraper

[![Promo](https://github.com/bright-kr/Amazon-scraper/blob/main/images/Proxies%20and%20scrapers%20GitHub%20bonus%20banner.png)](https://brightdata.co.kr/products/web-scraper/amazon?promo=github15) 

## Table of Contents

- [ë¬´ë£Œ Amazon Scraper](#free-amazon-scraper)
   - [ì‚¬ì „ ìš”êµ¬ ì‚¬í•­](#prerequisites)
   - [ë¹ ë¥¸ ì„¤ì •](#quick-setup)
   - [Amazon ë°ì´í„°ë¥¼ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•˜ëŠ” ë°©ë²•](#how-to-scrape-amazon-data)
   - [ì¶œë ¥](#output)
- [Amazon ë°ì´í„°ë¥¼ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•  ë•Œì˜ ê³¼ì œ](#challenges-when-scraping-amazon-data)
- [ì†”ë£¨ì…˜: Bright Data Amazon Scraper API](#solution-bright-data-amazon-scraper-api)
- [Amazon Scraper API ì‹¤ì œ ì‚¬ìš© ì˜ˆ](#amazon-scraper-api-in-action)
   - [API ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ë¡œ ë°ì´í„° ìˆ˜ì§‘ ì‚¬ìš©ì ì§€ì •](#customize-data-collection-with-api-parameters)
   - [Amazon ì œí’ˆ ë°ì´í„°](#amazon-product-data)
   - [Amazon ë¦¬ë·° ë°ì´í„°](#amazon-reviews-data)
   - [Amazon ì œí’ˆ ê²€ìƒ‰](#amazon-products-search)
   - [Amazon íŒë§¤ì ì •ë³´](#amazon-sellers-info)
   - [ë² ìŠ¤íŠ¸ì…€ëŸ¬ ê¸°ì¤€ Amazon ì œí’ˆ](#amazon-products-by-best-sellers)
   - [ì¹´í…Œê³ ë¦¬ URL ê¸°ì¤€ Amazon ì œí’ˆ](#amazon-products-by-category-url)
   - [í‚¤ì›Œë“œ ê¸°ì¤€ Amazon ì œí’ˆ](#amazon-products-by-keyword)
   - [Amazon ì œí’ˆ ê¸€ë¡œë²Œ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ](#amazon-products-global-dataset)
   - [Amazon ì œí’ˆ ê¸€ë¡œë²Œ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ - ì¹´í…Œê³ ë¦¬ URLë¡œ ë°œê²¬](#amazon-products-global-dataset---discover-by-category-url)
   - [Amazon ì œí’ˆ ê¸€ë¡œë²Œ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ - í‚¤ì›Œë“œë¡œ ë°œê²¬](#amazon-products-global-dataset---discover-by-keywords)


## Free Amazon Scraper
ì´ ë¬´ë£Œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ì—ì„œ Amazon ì œí’ˆ ë°ì´í„°ë¥¼ ì§ì ‘ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª‡ ê°€ì§€ ê°„ë‹¨í•œ ë‹¨ê³„ë§Œìœ¼ë¡œ ì œí’ˆ ì œëª©, ê°€ê²©, í‰ì , ë¦¬ë·° ë“± ë‹¤ì–‘í•œ ì •ë³´ë¥¼ ì†ì‰½ê²Œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Prerequisites
- Python 3.11 ì´ìƒ.
- í•„ìš”í•œ ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤(ì•„ë˜ ë‹¨ê³„ ì°¸ì¡°).

### Quick Setup
1. í„°ë¯¸ë„ì„ ì—´ê³  ì´ í”„ë¡œì íŠ¸ ë””ë ‰í„°ë¦¬ë¡œ ì´ë™í•©ë‹ˆë‹¤.
2. ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤:
   
    ```bash
    pip install -r requirements.txt
    ```

### How to Scrape Amazon Data
Amazon ë°ì´í„°ë¥¼ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•˜ë ¤ë©´ ê²€ìƒ‰ ì¿¼ë¦¬ë§Œ ì œê³µí•˜ë©´ ë©ë‹ˆë‹¤. ë˜í•œ Amazon ë„ë©”ì¸ê³¼ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•  í˜ì´ì§€ ìˆ˜ë¥¼ ì§€ì •í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

#### Command:
```bash
python main.py "<your_search_query>" --domain="<amazon_domain>" --pages=<number_of_pages>
```
- `<your_search_query>`: ê²€ìƒ‰ í‚¤ì›Œë“œ(ì˜ˆ: "coffee maker").
- `<amazon_domain>`: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•  Amazon ë„ë©”ì¸(ê¸°ë³¸ê°’: Amazon USì˜ `com`).
- `<number_of_pages>`: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•  í˜ì´ì§€ ìˆ˜(ì„ íƒ ì‚¬í•­ì´ë©°, ê¸°ë³¸ê°’ì€ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  í˜ì´ì§€ë¥¼ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•©ë‹ˆë‹¤).

#### Example:
Amazon US ë„ë©”ì¸ì—ì„œ "coffee maker" ë°ì´í„°ë¥¼ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•˜ê³  ê²°ê³¼ì˜ ì²˜ìŒ 3í˜ì´ì§€ë¥¼ ã‚¹ã‚¯ãƒ¬ã‚¤í•‘í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
ëª…ë ¹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
```bash
python main.py "coffee maker" --domain="com" --pages=3
```
### Output
ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° í›„ ì¶”ì¶œëœ ë°ì´í„°ëŠ” í”„ë¡œì íŠ¸ ë””ë ‰í„°ë¦¬ì— `amazon_data.csv`ë¡œ ì €ì¥ë©ë‹ˆë‹¤. CSV íŒŒì¼ì—ëŠ” ë‹¤ìŒ ì„¸ë¶€ ì •ë³´ê°€ í¬í•¨ë©ë‹ˆë‹¤:
- **Name:** ì œí’ˆ ì œëª©.
- **Current Price:** ì œí’ˆ ê°€ê²©(í’ˆì ˆì¸ ê²½ìš° ë¹„ì–´ ìˆìŒ).
- **Rating:** í‰ê·  ê³ ê° í‰ì .
- **Reviews:** ê³ ê° ë¦¬ë·° ì´ ê°œìˆ˜.
- **ASIN:** Amazon Standard Identification Number.
- **Link:** Amazonì˜ ì œí’ˆ í˜ì´ì§€ë¡œ ë°”ë¡œ ê°€ëŠ” URL.

ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í‘œì‹œë©ë‹ˆë‹¤:

<img width="700" alt="bright-data-amazon_csv_data" src="https://github.com/bright-kr/Amazon-scraper/blob/main/images/bright-data-amazon_csv_data.png">

## Challenges When Scraping Amazon Data
Amazon ë°ì´í„°ë¥¼ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•˜ëŠ” ì¼ì€ í•­ìƒ ê°„ë‹¨í•˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤. ë‹¤ìŒì€ ë§ˆì£¼ì¹  ìˆ˜ ìˆëŠ” ëª‡ ê°€ì§€ ê³¼ì œì…ë‹ˆë‹¤:
1. **ê³ ë„í™”ëœ ã‚¢ãƒ³ãƒãƒœãƒƒãƒˆ ì¡°ì¹˜:** Amazonì€ CAPTCHA, ë³´ì´ì§€ ì•ŠëŠ” ë´‡ íƒì§€ ê¸°ë²•, í–‰ë™ ë¶„ì„(ì˜ˆ: ë§ˆìš°ìŠ¤ ì›€ì§ì„ ì¶”ì  ë“±)ì„ ì‚¬ìš©í•˜ì—¬ ë´‡ì„ ì°¨ë‹¨í•©ë‹ˆë‹¤.
2. **ë¹ˆë²ˆí•œ í˜ì´ì§€ êµ¬ì¡° ì—…ë°ì´íŠ¸:** Amazonì€ HTML êµ¬ì¡°, ID, class ì´ë¦„ì„ ìì£¼ ë³€ê²½í•˜ë¯€ë¡œ ìƒˆë¡œìš´ í˜ì´ì§€ ë ˆì´ì•„ì›ƒì— ë§ì¶”ê¸° ìœ„í•´ ã‚¹ã‚¯ãƒ¬ã‚¤í¼ë¥¼ ì •ê¸°ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•´ì•¼ í•©ë‹ˆë‹¤.
3. **ë†’ì€ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰:** Playwright ë˜ëŠ” Selenium ê°™ì€ ë„êµ¬ë¡œ JavaScript ë¹„ì¤‘ì´ í° í˜ì´ì§€ë¥¼ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•˜ë©´ ìƒë‹¹í•œ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ë¥¼ ì†Œëª¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë™ì  ì½˜í…ì¸ ë¥¼ ì²˜ë¦¬í•˜ê³  ì—¬ëŸ¬ ë¸Œë¼ìš°ì € ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‹¤í–‰í•˜ë©´ íŠ¹íˆ ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•  ë•Œ ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì•„ë˜ëŠ” Amazonì´ ìë™í™”ëœ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° ì‹œë„ë¥¼ ê°ì§€í–ˆì„ ë•Œ ë°œìƒí•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤:

<img src="https://github.com/bright-kr/Amazon-scraper/blob/main/images/Amazon%20Blocked.png" alt="Amazon Blocked" width="700"/>

ìœ„ì—ì„œ ë³´ë“¯ì´ Amazonì€ ì¶”ê°€ ë°ì´í„° ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ë¦¬ã‚¯ãƒ¬ã‚¤ã‚¹ãƒˆë¥¼ ì°¨ë‹¨í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ë§ì€ ã‚¹ã‚¯ãƒ¬ã‚¤í¼ê°€ ê²ªëŠ” ì¼ë°˜ì ì¸ ë¬¸ì œì…ë‹ˆë‹¤.

## Solution: Bright Data Amazon Scraper API
[Bright Data Amazon Scraper API](https://brightdata.co.kr/products/web-scraper/amazon)ëŠ” ëŒ€ê·œëª¨ë¡œ Amazon ì œí’ˆ ë°ì´í„°ë¥¼ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•˜ê¸° ìœ„í•œ ê¶ê·¹ì ì¸ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤. ê·¸ ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

- **ã‚¤ãƒ³ãƒ•ãƒ© ê´€ë¦¬ ë¶ˆí•„ìš”**: ãƒ—ãƒ­ã‚­ã‚· ë˜ëŠ” ì–¸ë¸”ë¡œí‚¹ ì‹œìŠ¤í…œì„ ì²˜ë¦¬í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.
- **ã‚¸ã‚ªãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°**: ì–´ë–¤ ì§€ë¦¬ì  ì§€ì—­ì—ì„œë„ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- **ê¸€ë¡œë²Œ IP ì»¤ë²„ë¦¬ì§€**: 99.99% ì—…íƒ€ì„ìœ¼ë¡œ [195ê°œ êµ­ê°€](https://brightdata.co.kr/locations)ì˜ [7,200ë§Œ ê°œ ì´ìƒì˜ ì‹¤ì œ ì‚¬ìš©ì IP](https://brightdata.co.kr/proxy-types/residential-proxies)ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- **ìœ ì—°í•œ ë°ì´í„° ì „ë‹¬**: Amazon S3, Google Cloud, Azure, Snowflake ë˜ëŠ” SFTPë¥¼ í†µí•´ JSON, NDJSON, CSV, `.gz` ë“±ì˜ í˜•ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- **í”„ë¼ì´ë²„ì‹œ ì¤€ìˆ˜**: GDPR, CCPA ë° ê¸°íƒ€ ë°ì´í„° ë³´í˜¸ ë²•ë¥ ì„ ì™„ì „íˆ ì¤€ìˆ˜í•©ë‹ˆë‹¤.
- **24/7 ì§€ì›**: ì „ë‹´ ì§€ì› íŒ€ì´ 24ì‹œê°„ ì—°ì¤‘ë¬´íœ´ë¡œ API ê´€ë ¨ ì§ˆë¬¸ ë˜ëŠ” ë¬¸ì œë¥¼ ì§€ì›í•©ë‹ˆë‹¤.

ë˜í•œ ì œí’ˆì„ í…ŒìŠ¤íŠ¸í•˜ê³  ìš”êµ¬ ì‚¬í•­ì— ì–¼ë§ˆë‚˜ ì í•©í•œì§€ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ **ë¬´ë£Œ API í˜¸ì¶œ 20íšŒ**ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## Amazon Scraper API in Action

> Amazon Scraper API ì„¤ì •ì— ëŒ€í•œ ìì„¸í•œ ê°€ì´ë“œëŠ” [Step-by-Step Setup Guide](https://github.com/bright-kr/Amazon-scraper/blob/main/scraper_api_setup.md#amazon-reviews)ë¥¼ í™•ì¸í•˜ì‹­ì‹œì˜¤.

### Customize Data Collection with API Parameters

ë‹¤ìŒ API ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ìˆ˜ì§‘ì„ ì‚¬ìš©ì ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

| **Parameter**       | **Type**   | **Description**                                                                                   | **Example**                                           |
|---------------------|------------|---------------------------------------------------------------------------------------------------|-------------------------------------------------------|
| `limit`             | `integer`  | ê° ì…ë ¥ì— ëŒ€í•´ ë°˜í™˜ë˜ëŠ” ê²°ê³¼ ìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤.                                            | `limit=10`                                           |
| `include_errors`    | `boolean`   | ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ì¶œë ¥ì— ì˜¤ë¥˜ ë³´ê³ ì„œë¥¼ í¬í•¨í•©ë‹ˆë‹¤.                                      | `include_errors=true`                                |
| `notify`            | `url`      | ìˆ˜ì§‘ì´ ì™„ë£Œë˜ë©´ ì•Œë¦¼ì´ ì „ì†¡ë˜ëŠ” URLì…ë‹ˆë‹¤.                                  | `notify=https://notify-me.com/`                      |
| `format`            | `enum`     | ë°ì´í„° ì „ë‹¬ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: JSON, NDJSON, JSONL, CSV.                          | `format=json`                                        |

ğŸ’¡ì¶”ê°€ ì „ë‹¬ ë°©ë²•: [webhook](https://docs.brightdata.com/scraping-automation/web-data-apis/web-scraper-api/overview#via-webhook)ì„ í†µí•´ ë˜ëŠ” [API](https://docs.brightdata.com/scraping-automation/web-data-apis/web-scraper-api/overview#via-api)ë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ì „ë‹¬í•˜ë„ë¡ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Amazon Product Data
ì œí’ˆ URLì„ ì œê³µí•˜ì—¬ Amazonì˜ ìƒì„¸ ì œí’ˆ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

<img width="700" alt="bright-data-web-scraper-api-amazon-product-data" src="https://github.com/bright-kr/Amazon-scraper/blob/main/images/bright-data-web-scraper-api-amazon-product-data.png">

#### Key Input Parameters:
| Parameter | Type   | Description                    | Required |
|-----------|--------|--------------------------------|----------|
| `url`       | `string` | ë°ì´í„°ë¥¼ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•  Amazon ì œí’ˆ URL | Yes      |

#### Performance:
- ì…ë ¥ë‹¹ í‰ê·  ì‘ë‹µ ì‹œê°„: 13ì´ˆ

#### Sample Output Data:
Amazon ì œí’ˆ ë°ì´í„°ë¥¼ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•œ í›„ ë°›ê²Œ ë˜ëŠ” ì¶œë ¥ì˜ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
```json
{
    "url": "https://www.amazon.com/KitchenAid-Protective-Dishwasher-Stainless-8-72-Inch/dp/B07PZF3QS3",
    "title": "KitchenAid All Purpose Kitchen Shears with Protective Sheath...",
    "seller_name": "Amazon.com",
    "brand": "KitchenAid",
    "description": "These all-purpose shears from KitchenAid are a valuable addition...",
    "initial_price": 11.99,
    "final_price": 8.99,
    "currency": "USD",
    "availability": "In Stock",
    "reviews_count": 77557,
    "rating": 4.8,
    "categories": [
        "Home & Kitchen",
        "Kitchen & Dining",
        "Kitchen Utensils & Gadgets",
        "Shears"
    ],
    "asin": "B07PZF3QS3",
    "images": [
        "https://m.media-amazon.com/images/I/41E7ALk+uXL._AC_SL1200_.jpg",
        "https://m.media-amazon.com/images/I/710B9HpzMPL._AC_SL1500_.jpg"
    ],
    "delivery": [
        "FREE delivery Friday, October 25 on orders shipped by Amazon over $35",
        "Or fastest Same-Day delivery Today 10 AM - 3 PM. Order within 4 hrs 46 mins"
    ]
}
```
#### Code Example:
ì•„ë˜ëŠ” Amazon ì œí’ˆ ë°ì´í„° ìˆ˜ì§‘ì„ íŠ¸ë¦¬ê±°í•˜ê³  ê²°ê³¼ë¥¼ JSON íŒŒì¼ì— ì €ì¥í•˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤:
```python
import json
import requests
import time


def trigger_datasets(api_token, dataset_id, datasets):
    headers = {
        "Authorization": f"Bearer {api_token}",
        "Content-Type": "application/json",
    }

    trigger_url = (
        f"https://api.brightdata.com/datasets/v3/trigger?dataset_id={dataset_id}"
    )

    # Sending API request to trigger dataset collection
    response = requests.post(trigger_url, headers=headers, data=json.dumps(datasets))

    if response.status_code == 200:
        print("Data collection triggered successfully!")
        snapshot_id = response.json().get("snapshot_id")
        return snapshot_id if snapshot_id else print("No snapshot ID returned.")
    else:
        print(f"Error: {response.status_code} - {response.text}")
        return None


def get_snapshot_data(api_token, snapshot_id):
    headers = {"Authorization": f"Bearer {api_token}"}
    snapshot_url = (
        f"https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}?format=json"
    )

    # Polling until the snapshot data is ready
    while True:
        time.sleep(10)
        response = requests.get(snapshot_url, headers=headers)

        if response.status_code == 200:
            return response.json()
        elif response.status_code == 202:
            print("Snapshot still processing... retrying.")
        else:
            print(f"Error: {response.status_code} - {response.text}")
            return None


def store_data(data, filename="amazon_products_data.json"):
    if data:
        with open(filename, "w") as file:
            json.dump(data, file, indent=4)
        print(f"Data saved in {filename}.")
    else:
        print("No data to store.")


if __name__ == "__main__":
    API_TOKEN = "YOUR_API_TOKEN"
    DATASET_ID = "gd_l7q7dkf244hwjntr0"

    datasets = [
        {
            "url": "https://www.amazon.com/Quencher-FlowState-Stainless-Insulated-Smoothie/dp/B0CRMZHDG8"
        },
        {
            "url": "https://www.amazon.com/KitchenAid-Protective-Dishwasher-Stainless-8-72-Inch/dp/B07PZF3QS3"
        },
        {
            "url": "https://www.amazon.com/TruSkin-Naturals-Vitamin-Topical-Hyaluronic/dp/B01M4MCUAF"
        },
    ]

    # Trigger dataset collection
    snapshot_id = trigger_datasets(API_TOKEN, DATASET_ID, datasets)

    if snapshot_id:
        # Retrieve the data once the snapshot is ready
        data = get_snapshot_data(API_TOKEN, snapshot_id)
        if data:
            store_data(data)
```
ì „ì²´ ì¶œë ¥ì€ [ì´ ìƒ˜í”Œ JSON íŒŒì¼](https://github.com/bright-kr/Amazon-scraper/blob/main/output_data/amazon_products_data.json)ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Amazon Reviews Data
ì œí’ˆ URLê³¼ í•¨ê»˜ ê¸°ê°„, í‚¤ì›Œë“œ, ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•  ë¦¬ë·° ìˆ˜ ê°™ì€ íŠ¹ì • ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ë¥¼ ì œê³µí•˜ì—¬ Amazon ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

<img width="700" alt="bright-data-web-scraper-api-amazon-product-reviews" src="https://github.com/bright-kr/Amazon-scraper/blob/main/images/bright-data-web-scraper-api-amazon-product-reviews.png">


#### Key Input Parameters:
| **Parameter**       | **Type**  | **Description**                                                                 | **Required** |
|---------------------|-----------|---------------------------------------------------------------------------------|--------------|
| `url`               | `string`  | ë¦¬ë·°ë¥¼ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•  Amazon ì œí’ˆ URLì…ë‹ˆë‹¤.                             | Yes          |
| `days_range`        | `number`  | ë¦¬ë·° ìˆ˜ì§‘ ì‹œ ê³ ë ¤í•  ê³¼ê±° ì¼ìˆ˜(ì œí•œì´ ì—†ìœ¼ë©´ ë¹„ì›Œ ë‘¡ë‹ˆë‹¤). | No           |
| `keyword`           | `string`  | íŠ¹ì • í‚¤ì›Œë“œë¡œ ë¦¬ë·°ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤.                            | No           |
| `num_of_reviews`    | `number`  | ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•  ë¦¬ë·° ìˆ˜(ì œê³µí•˜ì§€ ì•Šìœ¼ë©´ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ë¦¬ë·°ë¥¼ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•©ë‹ˆë‹¤). | No           |

#### Performance:
- ì…ë ¥ë‹¹ í‰ê·  ì‘ë‹µ ì‹œê°„: 1ë¶„ 1ì´ˆ

#### Sample Output Data:
Amazon ë¦¬ë·°ë¥¼ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•  ë•Œ ë°›ê²Œ ë˜ëŠ” ì¶œë ¥ì˜ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
```json
{
    "url": "https://www.amazon.com/RORSOU-R10-Headphones-Microphone-Lightweight/dp/B094NC89P9/",
    "product_name": "RORSOU R10 On-Ear Headphones with Microphone...",
    "product_rating": 4.5,
    "product_rating_object": {
        "one_star": 386,
        "two_star": 237,
        "three_star": 584,
        "four_star": 1493,
        "five_star": 7630
    },
    "rating": 5,
    "author_name": "Amazon Customer",
    "review_header": "Great Sound For the Price!",
    "review_text": "I bought these headphones twice...",
    "badge": "Verified Purchase",
    "review_posted_date": "September 7, 2024",
    "helpful_count": 3
}
```
#### Code Example:
ì•„ë˜ëŠ” Amazon ë¦¬ë·° ë°ì´í„° ìˆ˜ì§‘ì„ íŠ¸ë¦¬ê±°í•˜ê³  ê²°ê³¼ë¥¼ JSON íŒŒì¼ì— ì €ì¥í•˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤:
```python
import json
import requests
import time


def trigger_datasets(api_token, dataset_id, datasets):
    headers = {
        "Authorization": f"Bearer {api_token}",
        "Content-Type": "application/json",
    }

    trigger_url = (
        f"https://api.brightdata.com/datasets/v3/trigger?dataset_id={dataset_id}"
    )

    # Sending API request to trigger dataset collection
    response = requests.post(trigger_url, headers=headers, data=json.dumps(datasets))

    if response.status_code == 200:
        print("Data collection triggered successfully!")
        snapshot_id = response.json().get("snapshot_id")
        return snapshot_id if snapshot_id else print("No snapshot ID returned.")
    else:
        print(f"Error: {response.status_code} - {response.text}")
        return None


def get_snapshot_data(api_token, snapshot_id):
    headers = {"Authorization": f"Bearer {api_token}"}
    snapshot_url = (
        f"https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}?format=json"
    )

    # Polling until the snapshot data is ready
    while True:
        time.sleep(10)
        response = requests.get(snapshot_url, headers=headers)

        if response.status_code == 200:
            return response.json()
        elif response.status_code == 202:
            print("Snapshot still processing... retrying.")
        else:
            print(f"Error: {response.status_code} - {response.text}")
            return None


def store_data(data, filename="amazon_reviews_data.json"):
    if data:
        with open(filename, "w") as file:
            json.dump(data, file, indent=4)
        print(f"Data saved in {filename}.")
    else:
        print("No data to store.")


if __name__ == "__main__":
    API_TOKEN = "YOUR_API_TOKEN"
    DATASET_ID = "gd_le8e811kzy4ggddlq"

    datasets = [
        {
            "url": "https://www.amazon.com/RORSOU-R10-Headphones-Microphone-Lightweight/dp/B094NC89P9/",
            "days_range": 0,
            "num_of_reviews": 4,
            "keyword": "great",
        },
        {
            "url": "https://www.amazon.com/Solar-Eclipse-Glasses-Certified-Viewing/dp/B08GB3QC1H",
            "days_range": 0,
            "num_of_reviews": 4,
            "keyword": "",
        },
    ]

    # Trigger dataset collection
    snapshot_id = trigger_datasets(API_TOKEN, DATASET_ID, datasets)

    if snapshot_id:
        # Retrieve the data once the snapshot is ready
        data = get_snapshot_data(API_TOKEN, snapshot_id)
        if data:
            store_data(data)
```
ì „ì²´ ì¶œë ¥ì€ [ì´ ìƒ˜í”Œ JSON íŒŒì¼](https://github.com/bright-kr/Amazon-scraper/blob/main/output_data/amazon_reviews_data.json)ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Amazon Products Search
ê²€ìƒ‰ì„ ìœ„í•œ í‚¤ì›Œë“œë¥¼ ì œê³µí•˜ì—¬ Amazon ì œí’ˆì„ ì°¾ìŠµë‹ˆë‹¤.

<img width="700" alt="bright-data-web-scraper-api-keyword-search" src="https://github.com/bright-kr/Amazon-scraper/blob/main/images/bright-data-web-scraper-api-keyword-search.png">

#### Key Input Parameters:
| Parameter         | Type    | Description                                 | Required |
|-------------------|---------|---------------------------------------------|----------|
| `keyword`         | string  | ì œí’ˆì„ ê²€ìƒ‰í•˜ëŠ” ë° ì‚¬ìš©í•˜ëŠ” í‚¤ì›Œë“œ      | Yes      |
| `url`             | string  | ê²€ìƒ‰í•  ë„ë©”ì¸ URL              | Yes      |
| `pages_to_search` | number  | ê²€ìƒ‰í•  í˜ì´ì§€ ìˆ˜        | No       |

#### Performance:
- ì…ë ¥ë‹¹ í‰ê·  ì‘ë‹µ ì‹œê°„: 1ì´ˆ

#### Sample Output Data:
Amazonì—ì„œ ì œí’ˆ í‚¤ì›Œë“œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•œ ë’¤ ë°›ê²Œ ë˜ëŠ” ì¶œë ¥ì˜ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
```json
{
    "asin": "B08H75RTZ8",
    "url": "https://www.amazon.com/Microsoft-Xbox-Gaming-Console-video-game/dp/B08H75RTZ8/ref=sr_1_1",
    "name": "Xbox Series X 1TB SSD Console - Includes Xbox Wireless Controller...",
    "sponsored": "false",
    "initial_price": 479,
    "final_price": 479,
    "currency": "USD",
    "sold": 2000,
    "rating": 4.8,
    "num_ratings": 28675,
    "variations": null,
    "badge": null,
    "brand": null,
    "delivery": ["FREE delivery"],
    "keyword": "X-box",
    "image": "https://m.media-amazon.com/images/I/616klipzdtL._AC_UY218_.jpg",
    "domain": "https://www.amazon.com/",
    "bought_past_month": 2000,
    "page_number": 1,
    "rank_on_page": 1,
    "timestamp": "2024-10-20T10:39:37.679Z",
    "input": {
        "keyword": "X-box",
        "url": "https://www.amazon.com",
        "pages_to_search": 1
    }
}
```
#### Code Example:
ì•„ë˜ëŠ” í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ Amazon ì œí’ˆ ê²€ìƒ‰ì„ íŠ¸ë¦¬ê±°í•˜ê³  ê²°ê³¼ë¥¼ JSON íŒŒì¼ì— ì €ì¥í•˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤:
```python
import json
import requests
import time


def trigger_datasets(api_token, dataset_id, datasets):
    headers = {
        "Authorization": f"Bearer {api_token}",
        "Content-Type": "application/json",
    }

    trigger_url = (
        f"https://api.brightdata.com/datasets/v3/trigger?dataset_id={dataset_id}"
    )

    # Sending API request to trigger dataset collection
    response = requests.post(trigger_url, headers=headers, data=json.dumps(datasets))

    if response.status_code == 200:
        print("Data collection triggered successfully!")
        snapshot_id = response.json().get("snapshot_id")
        return snapshot_id if snapshot_id else print("No snapshot ID returned.")
    else:
        print(f"Error: {response.status_code} - {response.text}")
        return None


def get_snapshot_data(api_token, snapshot_id):
    headers = {"Authorization": f"Bearer {api_token}"}
    snapshot_url = (
        f"https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}?format=json"
    )

    # Polling until the snapshot data is ready
    while True:
        response = requests.get(snapshot_url, headers=headers)

        if response.status_code == 200:
            return response.json()
        elif response.status_code == 202:
            print("Snapshot still processing... retrying.")
        else:
            print(f"Error: {response.status_code} - {response.text}")
            return None
        time.sleep(10)


def store_data(data, filename="amazon_keywords_data.json"):
    if data:
        with open(filename, "w") as file:
            json.dump(data, file, indent=4)
        print(f"Data saved in {filename}.")
    else:
        print("No data to store.")


if __name__ == "__main__":
    API_TOKEN = "YOUR_API_TOKEN"
    DATASET_ID = "gd_lwdb4vjm1ehb499uxs"

    datasets = [
        {"keyword": "X-box", "url": "https://www.amazon.com", "pages_to_search": 1},
        {"keyword": "PS5", "url": "https://www.amazon.de"},
        {
            "keyword": "car cleaning kit",
            "url": "https://www.amazon.es",
            "pages_to_search": 4,
        },
    ]

    # Trigger dataset collection
    snapshot_id = trigger_datasets(API_TOKEN, DATASET_ID, datasets)

    if snapshot_id:
        # Retrieve the data once the snapshot is ready
        data = get_snapshot_data(API_TOKEN, snapshot_id)
        if data:
            store_data(data)
```
ì „ì²´ ì¶œë ¥ì€ [ì´ ìƒ˜í”Œ JSON íŒŒì¼](https://github.com/bright-kr/Amazon-scraper/blob/main/output_data/amazon_keywords_data.json)ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Amazon Sellers Info
íŠ¹ì • íŒë§¤ì URLì„ ì œê³µí•˜ì—¬ Amazon íŒë§¤ìì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

<img width="700" alt="bright-data-web-scraper-api-seller-info" src="https://github.com/bright-kr/Amazon-scraper/blob/main/images/bright-data-web-scraper-api-seller-info.png">


#### Key Input Parameters:
| **Parameter** | **Type**  | **Description**                    | **Required** |
|---------------|-----------|------------------------------------|--------------|
| `url`         | `string`  | Amazon íŒë§¤ì URL              | Yes          |

#### Performance:
- ì…ë ¥ë‹¹ í‰ê·  ì‘ë‹µ ì‹œê°„: 1ì´ˆ

#### Sample Output Data:
íŒë§¤ì ì •ë³´ë¥¼ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•œ í›„ ë°›ê²Œ ë˜ëŠ” ì¶œë ¥ì˜ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
```json
{
    "input": {
        "url": "https://www.amazon.com/sp?seller=A33W53J5GVPZ8K"
    },
    "seller_id": "A33W53J5GVPZ8K",
    "seller_name": "Peckomatic",
    "description": "Peckomatic is committed to providing each customer with the highest standard of customer service.",
    "detailed_info": [
        {"title": "Business Name"},
        {"title": "Business Address"}
    ],
    "stars": "4.5 out of 5 stars",
    "feedbacks": [
        {
            "date": "By Kao y. on November 16, 2021.",
            "stars": "5 out of 5 stars",
            "text": "It say not to exceed 10lbs total but I did anyway. My bird was 8lbs + the 3lb box = 11lbs. Bird arrived in great condition."
        },
        {
            "date": "By JL on June 9, 2021.",
            "stars": "1 out of 5 stars",
            "text": "How this seller packages its items is not acceptable..."
        }
    ],
    "rating_positive": "89%",
    "feedbacks_percentages": {
        "star_5": "80%",
        "star_4": "9%",
        "star_3": "7%",
        "star_2": "0%",
        "star_1": "5%"
    },
    "products_link": "https://www.amazon.com/s?me=A33W53J5GVPZ8K",
    "buisness_name": "Francis Kunnumpurath",
    "buisness_address": "2612 State Route 80, Lafayette, NY, 13084, US",
    "rating_count_lifetime": 44,
    "country": "US"
}
```

#### Code Example:
ë‹¤ìŒì€ Amazon íŒë§¤ì ë°ì´í„° ìˆ˜ì§‘ì„ íŠ¸ë¦¬ê±°í•˜ê³  ê²°ê³¼ë¥¼ JSON íŒŒì¼ì— ì €ì¥í•˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤:
```python
import json
import requests
import time


def trigger_datasets(api_token, dataset_id, datasets):
    headers = {
        "Authorization": f"Bearer {api_token}",
        "Content-Type": "application/json",
    }

    trigger_url = (
        f"https://api.brightdata.com/datasets/v3/trigger?dataset_id={dataset_id}"
    )

    # Sending API request to trigger dataset collection
    response = requests.post(trigger_url, headers=headers, data=json.dumps(datasets))

    if response.status_code == 200:
        print("Data collection triggered successfully!")
        snapshot_id = response.json().get("snapshot_id")
        return snapshot_id if snapshot_id else print("No snapshot ID returned.")
    else:
        print(f"Error: {response.status_code} - {response.text}")
        return None


def get_snapshot_data(api_token, snapshot_id):
    headers = {"Authorization": f"Bearer {api_token}"}
    snapshot_url = (
        f"https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}?format=json"
    )

    # Polling until the snapshot data is ready
    while True:
        response = requests.get(snapshot_url, headers=headers)

        if response.status_code == 200:
            return response.json()
        elif response.status_code == 202:
            print("Snapshot still processing... retrying.")
        else:
            print(f"Error: {response.status_code} - {response.text}")
            return None
        time.sleep(10)


def store_data(data, filename="amazon_seller_data.json"):
    if data:
        with open(filename, "w") as file:
            json.dump(data, file, indent=4)
        print(f"Data saved in {filename}.")
    else:
        print("No data to store.")


if __name__ == "__main__":
    API_TOKEN = "API_TOKEN"
    DATASET_ID = "gd_lhotzucw1etoe5iw1k"

    # Define the dataset with seller URLs
    datasets = [
        {"url": "https://www.amazon.com/sp?seller=A33W53J5GVPZ8K"},
        {"url": "https://www.amazon.com/sp?seller=A33YXLPENB0JBD"},
        {"url": "https://www.amazon.com/sp?seller=A33ZG27WW2U3E6"},
    ]

    # Trigger dataset collection
    snapshot_id = trigger_datasets(API_TOKEN, DATASET_ID, datasets)

    if snapshot_id:
        # Retrieve the data once the snapshot is ready
        data = get_snapshot_data(API_TOKEN, snapshot_id)
        if data:
            store_data(data)
```

ì „ì²´ ì¶œë ¥ì€ [ì´ ìƒ˜í”Œ JSON íŒŒì¼](https://github.com/bright-kr/Amazon-scraper/blob/main/output_data/amazon_seller_data.json)ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Amazon Products by Best Sellers
ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì¹´í…Œê³ ë¦¬ì˜ URLì„ ì œê³µí•˜ì—¬ Amazonì—ì„œ ê°€ì¥ ë§ì´ íŒë§¤ë˜ëŠ” ì œí’ˆì„ í™•ì¸í•©ë‹ˆë‹¤.

<img width="700" alt="bright-data-web-scraper-api-amazon-best-sellers" src="https://github.com/bright-kr/Amazon-scraper/blob/main/images/bright-data-web-scraper-api-amazon-best-sellers.png">


#### Key Input Parameters:

| Parameter       | Type     | Description                                    | Required |
|-----------------|----------|------------------------------------------------|----------|
| `category_url`  | `string` | ë°ì´í„°ë¥¼ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•  ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì¹´í…Œê³ ë¦¬ URL | Yes      |

#### Performance:
- ì…ë ¥ë‹¹ í‰ê·  ì‘ë‹µ ì‹œê°„: 6ë¶„ 49ì´ˆ

#### Sample Output Data:
Amazonì˜ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ë°ì´í„°ë¥¼ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•œ í›„ ë°›ê²Œ ë˜ëŠ” ì¶œë ¥ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

```json
{
    "title": "Amazon Basics Multipurpose Copy Printer Paper, 8.5\" x 11\", 1 Ream, 500 Sheets, White",
    "seller_name": "Amazon.com",
    "brand": "Amazon Basics",
    "initial_price": 9.99,
    "final_price": 7.41,
    "currency": "USD",
    "availability": "In Stock",
    "reviews_count": 178695,
    "rating": 4.8,
    "categories": [
        "Office Products",
        "Paper",
        "Copy & Multipurpose Paper"
    ],
    "asin": "B01FV0F8H8",
    "buybox_seller": "Amazon.com",
    "discount": "-26%",
    "root_bs_rank": 1,
    "url": "https://www.amazon.com/AmazonBasics-Multipurpose-Copy-Printer-Paper/dp/B01FV0F8H8?th=1&psc=1",
    "image_url": "https://m.media-amazon.com/images/I/81x0cTHWQJL._AC_SL1500_.jpg",
    "delivery": [
        "FREE delivery Friday, October 25",
        "Same-Day delivery Today 10 AM - 3 PM"
    ],
    "features": [
        "1 ream (500 sheets) of 8.5 x 11 white copier and printer paper",
        "Works with laser/inkjet printers, copiers, and fax machines",
        "Smooth 20lb weight paper for consistent ink and toner distribution"
    ],
    "bought_past_month": 100000,
    "root_bs_category": "Office Products",
    "bs_category": "Copy & Multipurpose Paper",
    "bs_rank": 1,
    "amazon_choice": true,
    "badge": "Amazon's Choice",
    "seller_url": "https://www.amazon.com/sp?ie=UTF8&seller=ATVPDKIKX0DER&asin=B01FV0F8H8",
    "timestamp": "2024-10-20T13:30:56.666Z"
}
```
#### Code Example:
ì•„ë˜ëŠ” Amazon ë² ìŠ¤íŠ¸ì…€ëŸ¬ ë°ì´í„° ìˆ˜ì§‘ì„ íŠ¸ë¦¬ê±°í•˜ê³  ê²°ê³¼ë¥¼ JSON íŒŒì¼ì— ì €ì¥í•˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤:
```python
import json
import requests
import time


def trigger_datasets(api_token, dataset_id, datasets):
    headers = {
        "Authorization": f"Bearer {api_token}",
        "Content-Type": "application/json",
    }

    trigger_url = f"https://api.brightdata.com/datasets/v3/trigger?dataset_id={dataset_id}&type=discover_new&discover_by=best_sellers_url&limit_per_input=3"

    # Sending API request to trigger dataset collection
    response = requests.post(trigger_url, headers=headers, data=json.dumps(datasets))

    if response.status_code == 200:
        print("Data collection triggered successfully!")
        snapshot_id = response.json().get("snapshot_id")
        return snapshot_id if snapshot_id else print("No snapshot ID returned.")
    else:
        print(f"Error: {response.status_code} - {response.text}")
        return None


def get_snapshot_data(api_token, snapshot_id):
    headers = {"Authorization": f"Bearer {api_token}"}
    snapshot_url = (
        f"https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}?format=json"
    )

    # Polling until the snapshot data is ready
    while True:
        time.sleep(10)
        response = requests.get(snapshot_url, headers=headers)

        if response.status_code == 200:
            return response.json()
        elif response.status_code == 202:
            print("Snapshot still processing... retrying.")
        else:
            print(f"Error: {response.status_code} - {response.text}")
            return None


def store_data(data, filename="amazon_bestsellers_data.json"):
    if data:
        with open(filename, "w") as file:
            json.dump(data, file, indent=4)
        print(f"Data saved in {filename}.")
    else:
        print("No data to store.")


if __name__ == "__main__":
    API_TOKEN = "YOUR_API_TOKEN"
    DATASET_ID = "gd_l7q7dkf244hwjntr0"

    datasets = [
        {
            "category_url": "https://www.amazon.com/gp/bestsellers/office-products/ref=pd_zg_ts_office-products"
        },
    ]

    # Trigger dataset collection
    snapshot_id = trigger_datasets(API_TOKEN, DATASET_ID, datasets)

    if snapshot_id:
        # Retrieve the data once the snapshot is ready
        data = get_snapshot_data(API_TOKEN, snapshot_id)
        if data:
            store_data(data)
```
ì „ì²´ ì¶œë ¥ì€ [ì´ ìƒ˜í”Œ JSON íŒŒì¼](https://github.com/bright-kr/Amazon-scraper/blob/main/output_data/amazon_bestsellers.json)ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Amazon Products by Category URL
íŠ¹ì • ì¹´í…Œê³ ë¦¬ URLì„ ì œê³µí•˜ì—¬ Amazon ì œí’ˆ ë°ì´í„°ë¥¼ ë°œê²¬í•˜ê³  ìˆ˜ì§‘í•©ë‹ˆë‹¤. ì •ë ¬ ì˜µì…˜ê³¼ ìœ„ì¹˜ ê¸°ë°˜ í•„í„°ë¡œ ê²€ìƒ‰ì„ ì‚¬ìš©ì ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<img width="700" alt="bright-data-web-scraper-api-discover-by-category-url" src="https://github.com/bright-kr/Amazon-scraper/blob/main/images/bright-data-web-scraper-api-discover-by-category-url.png">

#### Key Input Parameters:
| **Parameter** | **Type**  | **Description**                              | **Required** |
|---------------|-----------|----------------------------------------------|--------------|
| `url`         | `string`  | ì œí’ˆì„ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•  ì¹´í…Œê³ ë¦¬ URL      | Yes          |
| `sort_by`     | `string`  | ì œí’ˆ ê²°ê³¼ ì •ë ¬ ê¸°ì¤€      | No           |
| `zipcode`     | `string`  | ìœ„ì¹˜ë³„ ì œí’ˆ ê²°ê³¼ë¥¼ ìœ„í•œ ìš°í¸ë²ˆí˜¸| No           |

#### Performance:
- ì…ë ¥ë‹¹ í‰ê·  ì‘ë‹µ ì‹œê°„: 16ë¶„ 16ì´ˆ

#### Sample Output Data:
ì§€ì •í•œ ì¹´í…Œê³ ë¦¬ì—ì„œ ì œí’ˆì„ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•œ í›„ ë°›ê²Œ ë˜ëŠ” ë°ì´í„° ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
```json
{
    "title": "Quilted Makeup Bag Floral Makeup Bag Cotton Makeup Bag",
    "brand": "WYJ",
    "price": 9.99,
    "currency": "USD",
    "availability": "In Stock",
    "rating": 5,
    "reviews_count": 1,
    "categories": [
        "Beauty & Personal Care",
        "Cosmetic Bags"
    ],
    "asin": "B0DC3WX7RM",
    "seller_name": "yisenshangmaoyouxiangongsi",
    "number_of_sellers": 1,
    "url": "https://www.amazon.com/WYJ-Quilted-Coquette-Aesthetic-Blue/dp/B0DC3WX7RM",
    "image_url": "https://m.media-amazon.com/images/I/71SI04tB6QL._AC_SL1500_.jpg",
    "product_dimensions": "8.7\"L x 2.8\"W x 5.1\"H",
    "item_weight": "2.5 Ounces",
    "variations": [
        {
            "name": "Pink",
            "asin": "B0DC3RKYPF",
            "price": 9.99
        },
        {
            "name": "Blue",
            "asin": "B0DC3WX7RM",
            "price": 9.99
        },
        {
            "name": "Purple",
            "asin": "B0DC47CDDT",
            "price": 9.99
        }
    ],
    "badge": "#1 New Release",
    "top_review": "I love everything about this bag! It's made well and a good size. Super cute!"
}
```

#### Code Example:
ì•„ë˜ëŠ” ì§€ì •í•œ ì¹´í…Œê³ ë¦¬ URLì—ì„œ ì œí’ˆ ìˆ˜ì§‘ì„ íŠ¸ë¦¬ê±°í•˜ê³  ë°ì´í„°ë¥¼ JSON íŒŒì¼ì— ì €ì¥í•˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤:
```python
import json
import requests
import time


def trigger_datasets(api_token, dataset_id, datasets):
    headers = {
        "Authorization": f"Bearer {api_token}",
        "Content-Type": "application/json",
    }

    trigger_url = f"https://api.brightdata.com/datasets/v3/trigger?dataset_id={dataset_id}&type=discover_new&discover_by=category_url&limit_per_input=4"

    # Sending API request to trigger dataset collection
    response = requests.post(trigger_url, headers=headers, data=json.dumps(datasets))

    if response.status_code == 200:
        print("Data collection triggered successfully!")
        snapshot_id = response.json().get("snapshot_id")
        return snapshot_id if snapshot_id else print("No snapshot ID returned.")
    else:
        print(f"Error: {response.status_code} - {response.text}")
        return None


def get_snapshot_data(api_token, snapshot_id):
    headers = {"Authorization": f"Bearer {api_token}"}
    snapshot_url = (
        f"https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}?format=json"
    )

    # Polling until the snapshot data is ready
    while True:
        response = requests.get(snapshot_url, headers=headers)

        if response.status_code == 200:
            return response.json()
        elif response.status_code == 202:
            print("Snapshot still processing... retrying.")
        else:
            print(f"Error: {response.status_code} - {response.text}")
            return None
        time.sleep(10)


def store_data(data, filename="amazon_bestsellers_data.json"):
    if data:
        with open(filename, "w") as file:
            json.dump(data, file, indent=4)
        print(f"Data saved in {filename}.")
    else:
        print("No data to store.")


if __name__ == "__main__":
    API_TOKEN = "YOUR_API_TOKEN"
    DATASET_ID = "gd_l7q7dkf244hwjntr0"

    datasets = [
        {
            "url": "https://www.amazon.com/s?i=luggage-intl-ship",
            "sort_by": "Best Sellers",
            "zipcode": "10001",
        },
        {
            "url": "https://www.amazon.com/s?i=baby-products-intl-ship",
            "sort_by": "Avg. Customer Review",
            "zipcode": "",
        },
        {
            "url": "https://www.amazon.com/s?rh=n%3A16225012011&fs=true&ref=lp_16225012011_sar",
            "sort_by": "Price: Low to High",
            "zipcode": "",
        },
    ]

    # Trigger dataset collection
    snapshot_id = trigger_datasets(API_TOKEN, DATASET_ID, datasets)

    if snapshot_id:
        # Retrieve the data once the snapshot is ready
        data = get_snapshot_data(API_TOKEN, snapshot_id)
        if data:
            store_data(data)
```

ì „ì²´ ì¶œë ¥ì€ [ì´ ìƒ˜í”Œ JSON íŒŒì¼](https://github.com/bright-kr/Amazon-scraper/blob/main/output_data/amazon_discover_by_category_url.json)ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Amazon Products by Keyword
íŠ¹ì • í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì œí’ˆì„ ë°œê²¬í•©ë‹ˆë‹¤.

<img width="700" alt="bright-data-web-scraper-api-discover-by-keyword" src="https://github.com/bright-kr/Amazon-scraper/blob/main/images/bright-data-web-scraper-api-discover-by-keyword.png">

#### Key Input Parameters:
| **Parameter** | **Type**  | **Description**                   | **Required** |
|---------------|-----------|-----------------------------------|--------------|
| `keyword`     | `string`  | ì œí’ˆì„ ê²€ìƒ‰í•  í‚¤ì›Œë“œ | Yes          |

#### Performance:
- ì…ë ¥ë‹¹ í‰ê·  ì‘ë‹µ ì‹œê°„: 2ë¶„ 46ì´ˆ

#### Sample Output Data:
í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì œí’ˆì„ ê²€ìƒ‰í•œ í›„ ë°›ê²Œ ë˜ëŠ” ì¶œë ¥ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

```json
{
    "title": "SYLVANIA ECO LED Light Bulb, A19 60W Equivalent, 750 Lumens, 2700K, Non-Dimmable, Frosted, Soft White - 8 Count (Pack of 1)",
    "brand": "LEDVANCE",
    "seller_name": "Amazon.com",
    "initial_price": 13.99,
    "final_price": 12.12,
    "currency": "USD",
    "discount": "-13%",
    "rating": 4.7,
    "reviews_count": 48418,
    "availability": "In Stock",
    "url": "https://www.amazon.com/Sylvania-40821-Equivalent-Efficient-Temperature/dp/B08FRSS4BF",
    "image_url": "https://m.media-amazon.com/images/I/81wKhRO66oL._AC_SL1500_.jpg",
    "delivery": [
        "FREE delivery Friday, October 25 on orders shipped by Amazon over $35",
        "Or Prime members get FREE delivery Tomorrow, October 21. Order within 8 hrs 8 mins. Join Prime"
    ],
    "features": [
        "60W Incandescent Replacement Bulb - 750 Lumens",
        "Long-lasting â€“ 7 years lifespan",
        "Energy-saving â€“ Estimated energy cost of $1.08 per year"
    ],
    "discovery_input": {
        "keyword": "light bulb"
    },
    "input": {
        "url": "https://www.amazon.com/Sylvania-40821-Equivalent-Efficient-Temperature/dp/B08FRSS4BF"
    }
}
```
#### Code Example:
ì•„ë˜ëŠ” í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ Amazon ì œí’ˆ ìˆ˜ì§‘ì„ íŠ¸ë¦¬ê±°í•˜ê³  ê²°ê³¼ë¥¼ JSON íŒŒì¼ì— ì €ì¥í•˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤:
```python
import json
import requests
import time


def trigger_datasets(
    api_token, dataset_id, datasets, dataset_type="discover_new", discover_by="keyword"
):
    headers = {
        "Authorization": f"Bearer {api_token}",
        "Content-Type": "application/json",
    }

    trigger_url = f"https://api.brightdata.com/datasets/v3/trigger?dataset_id={dataset_id}&type={dataset_type}&discover_by={discover_by}"

    # Sending API request to trigger dataset collection
    response = requests.post(trigger_url, headers=headers, data=json.dumps(datasets))

    if response.status_code == 200:
        print("Data collection triggered successfully!")
        snapshot_id = response.json().get("snapshot_id")
        return snapshot_id if snapshot_id else print("No snapshot ID returned.")
    else:
        print(f"Error: {response.status_code} - {response.text}")
        return None


def get_snapshot_data(api_token, snapshot_id):
    headers = {"Authorization": f"Bearer {api_token}"}
    snapshot_url = (
        f"https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}?format=json"
    )

    # Polling until the snapshot data is ready
    while True:
        response = requests.get(snapshot_url, headers=headers)

        if response.status_code == 200:
            return response.json()
        elif response.status_code == 202:
            print("Snapshot still processing... retrying.")
        else:
            print(f"Error: {response.status_code} - {response.text}")
            return None
        time.sleep(10)


def store_data(data, filename="amazon_keyword_data.json"):
    if data:
        with open(filename, "w") as file:
            json.dump(data, file, indent=4)
        print(f"Data saved in {filename}.")
    else:
        print("No data to store.")


if __name__ == "__main__":
    API_TOKEN = "API_TOKEN"
    DATASET_ID = "gd_l7q7dkf244hwjntr0"

    # Define the dataset with keywords
    datasets = [{"keyword": "light bulb"}, {"keyword": "dog toys"}]

    # Trigger dataset collection
    snapshot_id = trigger_datasets(API_TOKEN, DATASET_ID, datasets)

    if snapshot_id:
        # Retrieve the data once the snapshot is ready
        data = get_snapshot_data(API_TOKEN, snapshot_id)
        if data:
            store_data(data)
```

ì „ì²´ ì¶œë ¥ì€ [ì´ ìƒ˜í”Œ JSON íŒŒì¼](https://github.com/bright-kr/Amazon-scraper/blob/main/output_data/amazon_keyword_data.json)ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Amazon Products Global Dataset
URLì„ ì œê³µí•˜ì—¬ ì£¼ìš” Amazon ë„ë©”ì¸ ì „ë°˜ì—ì„œ ì œí’ˆ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

<img width="700" alt="bright-data-web-scraper-api-amazon-product-global-dataset" src="https://github.com/bright-kr/Amazon-scraper/blob/main/images/bright-data-web-scraper-api-amazon-product-global-dataset.png">


#### Key Input Parameters:
| **Parameter** | **Type**  | **Description**           | **Required** |
|---------------|-----------|---------------------------|--------------|
| `url`         | `string`  | Amazon ì œí’ˆ URL     | Yes          |

#### Performance:
- **ì…ë ¥ë‹¹ í‰ê·  ì‘ë‹µ ì‹œê°„**: 1ì´ˆ ë¯¸ë§Œ

#### Sample Output Data:
ì œí’ˆ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•œ í›„ ë°›ê²Œ ë˜ëŠ” ì¶œë ¥ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

```json
{
    "title": "Toys of Wood Oxford Wooden Stacking Rings â€“ Learning to Count â€“ Counting Game with 45 Rings â€“ Wooden Toy for Ages 3 and Above",
    "brand": "Toys of Wood Oxford",
    "seller_name": "Toys of Wood Oxford",
    "initial_price": 23.99,
    "currency": "EUR",
    "final_price": 23.99,
    "availability": "Only 20 left in stock.",
    "rating": 4.5,
    "reviews_count": 1677,
    "asin": "B078TNNZK3",
    "url": "https://www.amazon.de/dp/B078TNNZK3?th=1&psc=1",
    "image_url": "https://m.media-amazon.com/images/I/815t1-d+7BL._AC_SL1500_.jpg",
    "product_dimensions": "43.31 x 11.61 x 11.51 cm; 830 g",
    "categories": [
        "Toys",
        "Baby & Toddler Toys",
        "Early Development & Activity Toys",
        "Sorting, Stacking & Plugging Toys"
    ],
    "delivery": [
        "FREE delivery Friday, 25 October on eligible first order",
        "Or fastest delivery Thursday, 24 October. Order within 4 hrs 40 mins"
    ],
    "features": [
        "Sturdy and stable base plate with 9 pins and 45 beautiful large wooden rings and 10 removable square number plates in rainbow colours.",
        "Great for learning counting, sorting, and matching colors and numbers, as well as practicing simple mathematics.",
        "Made from sustainable wood with eco-friendly and non-toxic paints. Complies with EN71 / CPSA standards."
    ],
    "top_review": "Sehr lehrreich",
    "variations": [
        {
            "name": "Caterpillar Threading Toy",
            "price": 13.99,
            "currency": "EUR"
        },
        {
            "name": "Pack of 15",
            "price": 16.99,
            "currency": "EUR"
        },
        {
            "name": "Pack of 45",
            "price": 23.99,
            "currency": "EUR"
        }
    ],
    "product_rating_object": {
        "one_star": 35,
        "two_star": 0,
        "three_star": 82,
        "four_star": 227,
        "five_star": 1308
    }
}
```
#### Code Example:
ì•„ë˜ëŠ” ì£¼ìš” Amazon ë„ë©”ì¸ ì „ë°˜ì—ì„œ ì œí’ˆ ìˆ˜ì§‘ì„ íŠ¸ë¦¬ê±°í•˜ê³  ê²°ê³¼ë¥¼ JSON íŒŒì¼ì— ì €ì¥í•˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤:
```python
import json
import requests
import time


def trigger_datasets(
    api_token, dataset_id, datasets, dataset_type="trigger", discover_by="url"
):
    headers = {
        "Authorization": f"Bearer {api_token}",
        "Content-Type": "application/json",
    }

    trigger_url = f"https://api.brightdata.com/datasets/v3/trigger?dataset_id={
        dataset_id}&type={dataset_type}&discover_by={discover_by}"

    # Sending API request to trigger dataset collection
    response = requests.post(trigger_url, headers=headers, data=json.dumps(datasets))

    if response.status_code == 200:
        print("Data collection triggered successfully!")
        snapshot_id = response.json().get("snapshot_id")
        return snapshot_id if snapshot_id else print("No snapshot ID returned.")
    else:
        print(f"Error: {response.status_code} - {response.text}")
        return None


def get_snapshot_data(api_token, snapshot_id):
    headers = {"Authorization": f"Bearer {api_token}"}
    snapshot_url = f"https://api.brightdata.com/datasets/v3/snapshot/{
        snapshot_id}?format=json"

    # Polling until the snapshot data is ready
    while True:
        response = requests.get(snapshot_url, headers=headers)

        if response.status_code == 200:
            return response.json()
        elif response.status_code == 202:
            print("Snapshot still processing... retrying.")
        else:
            print(f"Error: {response.status_code} - {response.text}")
            return None
        time.sleep(10)


def store_data(data, filename="amazon_products_global_dataset.json"):
    if data:
        with open(filename, "w") as file:
            json.dump(data, file, indent=4)
        print(f"Data saved in {filename}.")
    else:
        print("No data to store.")


if __name__ == "__main__":
    API_TOKEN = "API_TOKEN"
    DATASET_ID = "gd_lwhideng15g8jg63s7"

    # Define the dataset with URLs
    datasets = [
        {"url": "https://www.amazon.com/dp/B0CHHSFMRL/"},
        {
            "url": "https://www.amazon.de/-/en/dp/B078TNNZK3/ref=sspa_dk_browse_2/?_encoding=UTF8&ie=UTF8&sp_csd=d2lkZ2V0TmFtZT1zcF9icm93c2VfdGhlbWF0aWM%3D&pd_rd_w=fHlOu&content-id=amzn1.sym.642a11a6-0e1e-47fa-93c2-5dc9d607a7a1&pf_rd_p=642a11a6-0e1e-47fa-93c2-5dc9d607a7a1&pf_rd_r=4JX920KFM8Q7PR83HJ7V&pd_rd_wg=K1OVN&pd_rd_r=be656f87-1a09-4144-b7cf-4e932d6a73c4&ref_=sspa_dk_browse&th=1"
        },
        {
            "url": "https://www.amazon.co.jp/X-TRAK-Folding-Bicycle-Carbon-Adjustable/dp/B0CWV9YTLV/ref=sr_1_1_sspa?crid=3MKZ2ALHSLFOM&dib=eyJ2IjoiMSJ9.YnBVPwJ7nLxlNGHktwDTFM5v2evnsXlnZTJHJKuG8dLeeRCILpy0Knr3ofiKpUGQYi6xR6y4tgdtal85DJ8u6DD_n9r1oVCXdVo0NFmNAfStU6E-MhBig5p_gZGjluAYv5HgUIoEPl0v3iMiRxZNRfivqB-utxOkPOOfXIBHLemry17XcltUDTQqtJv-kP-ZqdP29mjD2cRlbkALtHPKU44MvBC9WUrNcUHAMrlAxtTAByuriywMqz-w2P0HCeehcZTJ1EiLf2VR8cxCiwuaUbIOU3tr1kDN6D7yYPrgRn4.6AOdSmJsksZkqLg8kNM6EvWxIFOijCsP2zo5NLHn1P4&dib_tag=se&keywords=Bicycles&qid=1716973495&sprefix=%2Caps%2C851&sr=8-1-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&psc=1"
        },
        {
            "url": "https://www.amazon.in/Watches-Women%EF%BC%8CLadies-Stainless-Waterproof-Luminous/dp/B0D31HBWG1/ref=sr_1_2_sspa?dib=eyJ2IjoiMSJ9.1zFa2vTCZdD-bv6Knt_pWqvcRZPSSTPDwgMClRJNsWqdyGdCmryjEAfWpd-ZhwhC3vvNx9A0G2Gt1R952e7huzlukge2bmJETNf-kHBoWS5kV6g0pUVapEyDOEAGcw5ZvWlkeuLQ9oIwuhckRC6ARCt2yglYV-1HpP7lVGXotK6K6tjrdKxUSAOZJSXeOGP3dGuYPTjo9sllOrwA7FC2GG00aDcsSTzURENFj1c2rS-vNHkYmxOL1JYuwDWK2PJdMpsmkJw3jeMdgaiw7jG5ppMfAjwiETVldQzhHGVUFV8.manfNZwtTUhvDuSGdh32APM1_SmnNiKgOGabyA7rXBo&dib_tag=se&qid=1716973272&rnid=2563505031&s=watch&sr=1-2-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGZfYnJvd3Nl&psc=1"
        },
    ]

    # Trigger dataset collection
    snapshot_id = trigger_datasets(API_TOKEN, DATASET_ID, datasets)

    if snapshot_id:
        # Retrieve the data once the snapshot is ready
        data = get_snapshot_data(API_TOKEN, snapshot_id)
        if data:
            store_data(data)
```

ì „ì²´ ì¶œë ¥ì€ [ì´ ìƒ˜í”Œ JSON íŒŒì¼](https://github.com/bright-kr/Amazon-scraper/blob/main/output_data/amazon_products_global_dataset.json)ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Amazon Products Global Dataset - Discover by Category URL
íŠ¹ì • ì¹´í…Œê³ ë¦¬ URLì„ ì œê³µí•˜ì—¬ ì œí’ˆì„ ë°œê²¬í•©ë‹ˆë‹¤.

<img width="700" alt="bright-data-web-scraper-api-amazon-product-global-category-url" src="https://github.com/bright-kr/Amazon-scraper/blob/main/images/bright-data-web-scraper-api-amazon-product-global-category-url.png">


#### Key Input Parameters:
| **Parameter** | **Type** | **Description**                               | **Required** |
|---------------|----------|-----------------------------------------------|--------------|
| `url`         | `string` | ì œí’ˆì„ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°í•  ì¹´í…Œê³ ë¦¬ URL | Yes          |
| `sort_by`     | `string` |Criteria for sorting the results               | No           |
| `zipcode`     | `string` | ìœ„ì¹˜ë³„ ê²°ê³¼ë¥¼ ìœ„í•œ ìš°í¸ë²ˆí˜¸         | No           |

#### Performance:
- ì…ë ¥ë‹¹ í‰ê·  ì‘ë‹µ ì‹œê°„: 3ë¶„ 57ì´ˆ

#### Sample Output Data:
ì œí’ˆ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•œ í›„ ë°›ê²Œ ë˜ëŠ” ì¶œë ¥ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
```json
{
    "title": "De'Longhi Stilosa EC230.BK, Traditional Barista Pump Espresso Machine, Espresso and Cappuccino, 2 cups, Black",
    "brand": "De'Longhi",
    "seller_name": "Hughes Electrical",
    "initial_price": 104.99,
    "final_price": 94,
    "currency": "GBP",
    "availability": "Only 1 left in stock.",
    "rating": 3.9,
    "reviews_count": 395,
    "asin": "B085J8LV4F",
    "url": "https://www.amazon.co.uk/dp/B085J8LV4F?th=1&psc=1",
    "image_url": "https://m.media-amazon.com/images/I/715gqhkOEiL._AC_SL1500_.jpg",
    "categories": [
        "Cooking & Dining",
        "Coffee, Tea & Espresso",
        "Coffee Machines",
        "Espresso & Cappuccino Machines"
    ],
    "delivery": [
        "FREE delivery 25 - 28 October",
        "Or fastest delivery Tomorrow, 22 October. Order within 3 hrs 59 mins"
    ],
    "features": [
        "Unleash your inner barista and create all your coffee shop favourites at home",
        "15-bar pump espresso maker with a stainless steel boiler for perfect coffee extraction",
        "Steam arm to create frothy cappuccinos and smooth lattes",
        "Combination of matt and glossy black finish with an anti-drip system"
    ],
    "input": {
        "url": "https://www.amazon.co.uk/DeLonghi-EC230-BK-Traditional-Espresso-Cappuccino/dp/B085J8LV4F/ref=sr_1_4"
    },
    "discovery_input": {
        "url": "https://www.amazon.co.uk/b/?_encoding=UTF8&node=10706951&ref_=Oct_d_odnav_d_13528598031_1",
        "sort_by": "Best Sellers",
        "zipcode": ""
    }
}
```
#### Code Example:
ì•„ë˜ëŠ” ì¹´í…Œê³ ë¦¬ URLë¡œ ì œí’ˆ ìˆ˜ì§‘ì„ íŠ¸ë¦¬ê±°í•˜ê³  ê²°ê³¼ë¥¼ JSON íŒŒì¼ì— ì €ì¥í•˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤:
```python
import json
import requests
import time


def trigger_datasets(api_token, dataset_id, datasets, dataset_type="discover_new", discover_by="category_url", limit_per_input=4):
    headers = {
        "Authorization": f"Bearer {api_token}",
        "Content-Type": "application/json",
    }

    trigger_url = f"https://api.brightdata.com/datasets/v3/trigger?dataset_id={dataset_id}&type={
        dataset_type}&discover_by={discover_by}&limit_per_input={limit_per_input}"

    # Sending API request to trigger dataset collection
    response = requests.post(
        trigger_url, headers=headers, data=json.dumps(datasets))

    if response.status_code == 200:
        print("Data collection triggered successfully!")
        snapshot_id = response.json().get("snapshot_id")
        return snapshot_id if snapshot_id else print("No snapshot ID returned.")
    else:
        print(f"Error: {response.status_code} - {response.text}")
        return None


def get_snapshot_data(api_token, snapshot_id):
    headers = {"Authorization": f"Bearer {api_token}"}
    snapshot_url = f"https://api.brightdata.com/datasets/v3/snapshot/{
        snapshot_id}?format=json"

    # Polling until the snapshot data is ready
    while True:
        response = requests.get(snapshot_url, headers=headers)

        if response.status_code == 200:
            return response.json()
        elif response.status_code == 202:
            print("Snapshot still processing... retrying.")
        else:
            print(f"Error: {response.status_code} - {response.text}")
            return None
        time.sleep(10)


def store_data(data, filename="amazon_category_url_data.json"):
    if data:
        with open(filename, "w") as file:
            json.dump(data, file, indent=4)
        print(f"Data saved in {filename}.")
    else:
        print("No data to store.")


if __name__ == "__main__":
    API_TOKEN = "API_TOKEN"
    DATASET_ID = "gd_lwhideng15g8jg63s7"

    # Define the dataset with category URLs, sort_by, and zipcodes
    datasets = [
        {"url": "https://www.amazon.com/s?i=luggage-intl-ship",
            "sort_by": "Featured", "zipcode": "10001"},
        {"url": "https://www.amazon.de/-/en/b/?node=1981001031&ref_=Oct_d_odnav_d_355007011_2&pd_rd_w=OjE3S&content-id=amzn1.sym.0069bc39-a323-47d6-a8fb-7558e4a563e4&pf_rd_p=0069bc39-a323-47d6-a8fb-7558e4a563e4&pf_rd_r=6YXZ7HGFNNEAF0GSDPDH&pd_rd_wg=0yR1G&pd_rd_r=a95cb46c-78ef-4b7b-845d-49fe04556440", "sort_by": "Price: Low to High", "zipcode": ""},
        {"url": "https://www.amazon.co.uk/b/?_encoding=UTF8&node=10706951&bbn=11052681&ref_=Oct_d_odnav_d_13528598031_1&pd_rd_w=LghVp&content-id=amzn1.sym.7414f21e-2c95-4394-9a75-8c1b3641bcea&pf_rd_p=7414f21e-2c95-4394-9a75-8c1b3641bcea&pf_rd_r=EE0PQWMSY2J0G8M032EB&pd_rd_wg=7snrU&pd_rd_r=349e1e79-8bf8-4e00-947d-17eab2942b8d", "sort_by": "Best Sellers", "zipcode": ""},
        {"url": "https://www.amazon.co.jp/-/en/b/?node=377403011&ref_=Oct_d_odnav_d_15314601_0&pd_rd_w=ajUV4&content-id=amzn1.sym.0d505cca-fde9-497c-b5f8-e827c26fad17&pf_rd_p=0d505cca-fde9-497c-b5f8-e827c26fad17&pf_rd_r=92HSETNKKN3RTA615BV7&pd_rd_wg=AwOOk&pd_rd_r=629211d8-6768-478c-94a2-829a0a0ca2a6", "sort_by": "", "zipcode": ""}
    ]

    # Trigger dataset collection
    snapshot_id = trigger_datasets(API_TOKEN, DATASET_ID, datasets)

    if snapshot_id:
        # Retrieve the data once the snapshot is ready
        data = get_snapshot_data(API_TOKEN, snapshot_id)
        if data:
            store_data(data)
```
ì „ì²´ ì¶œë ¥ì€ [ì´ ìƒ˜í”Œ JSON íŒŒì¼](https://github.com/bright-kr/Amazon-scraper/blob/main/output_data/amazon_product_global_category_url.json)ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Amazon Products Global Dataset - Discover by Keywords
Amazon ë„ë©”ì¸ ì „ë°˜ì—ì„œ íŠ¹ì • í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì œí’ˆì„ ë°œê²¬í•©ë‹ˆë‹¤.

<img width="700" alt="bright-data-web-scraper-api-amazon_global_dataset_by_keyword" src="https://github.com/bright-kr/Amazon-scraper/blob/main/images/bright-data-web-scraper-api-amazon_global_dataset_by_keyword.png">

#### Key Input Parameters:
| **Parameter**      | **Type**   | **Description**                            | **Required** |
|--------------------|------------|--------------------------------------------|--------------|
| `keywords`         | `string`   | ì œí’ˆì„ ê²€ìƒ‰í•  í‚¤ì›Œë“œ         | Yes          |
| `domain`           | `string`   | ê²€ìƒ‰í•  Amazon ë„ë©”ì¸             | Yes          |
| `pages_to_search`  | `number`   | ê²€ìƒ‰í•  í˜ì´ì§€ ìˆ˜                  | No           |

#### Performance:
- ì…ë ¥ë‹¹ í‰ê·  ì‘ë‹µ ì‹œê°„: 56ì´ˆ

#### Sample Output Data:
í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ ì œí’ˆì„ ê²€ìƒ‰í•œ í›„ ë°›ê²Œ ë˜ëŠ” ì¶œë ¥ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
```json
{
    "title": "Mitutoyo 500-197-30 Electronic Digital Caliper AOS Absolute Scale Digital Caliper, 0 to 8\"/0 to 200mm Measuring Range, 0.0005\"/0.01mm Resolution",
    "brand": "Mitutoyo",
    "seller_name": "Everly Home & Gift",
    "initial_price": 157.97,
    "final_price": 137.77,
    "currency": "USD",
    "availability": "In Stock",
    "rating": 4.8,
    "reviews_count": 88,
    "asin": "B01N6C3EGR",
    "url": "https://www.amazon.com/dp/B01N6C3EGR?th=1&psc=1",
    "image_url": "https://m.media-amazon.com/images/I/61Gigoh3LbL._SL1500_.jpg",
    "categories": [
        "Industrial & Scientific",
        "Test, Measure & Inspect",
        "Dimensional Measurement",
        "Calipers",
        "Digital Calipers"
    ],
    "delivery": [
        "FREE delivery Saturday, October 26",
        "Or Prime members get FREE delivery Tomorrow, October 22"
    ],
    "features": [
        "Hardened stainless steel construction for protection of caliper components",
        "Digital, single-value readout LCD display in metric units for readability",
        "Measuring Range 0 to 8\"/0 to 200mm",
        "Measurement Accuracy +/-0.001",
        "Resolution 0.0005\"/0.01mm"
    ],
    "input": {
        "url": "https://www.amazon.com/Mitutoyo-500-197-30-Electronic-Measuring-Resolution/dp/B01N6C3EGR"
    },
    "discovery_input": {
        "keywords": "Mitutoyo",
        "domain": "https://www.amazon.com",
        "pages_to_search": 1
    }
}
```
#### Code Example:
ì•„ë˜ëŠ” í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ ì œí’ˆ ìˆ˜ì§‘ì„ íŠ¸ë¦¬ê±°í•˜ê³  ê²°ê³¼ë¥¼ JSON íŒŒì¼ì— ì €ì¥í•˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤:
```python
import json
import requests
import time


def trigger_datasets(
    api_token, dataset_id, datasets, dataset_type="discover_new", discover_by="keywords"
):
    headers = {
        "Authorization": f"Bearer {api_token}",
        "Content-Type": "application/json",
    }

    trigger_url = f"https://api.brightdata.com/datasets/v3/trigger?dataset_id={
        dataset_id}&type={dataset_type}&discover_by={discover_by}"

    # Sending API request to trigger dataset collection
    response = requests.post(trigger_url, headers=headers, data=json.dumps(datasets))

    if response.status_code == 200:
        print("Data collection triggered successfully!")
        snapshot_id = response.json().get("snapshot_id")
        return snapshot_id if snapshot_id else print("No snapshot ID returned.")
    else:
        print(f"Error: {response.status_code} - {response.text}")
        return None


def get_snapshot_data(api_token, snapshot_id):
    headers = {"Authorization": f"Bearer {api_token}"}
    snapshot_url = f"https://api.brightdata.com/datasets/v3/snapshot/{
        snapshot_id}?format=json"

    # Polling until the snapshot data is ready
    while True:
        response = requests.get(snapshot_url, headers=headers)

        if response.status_code == 200:
            return response.json()
        elif response.status_code == 202:
            print("Snapshot still processing... retrying.")
        else:
            print(f"Error: {response.status_code} - {response.text}")
            return None
        time.sleep(10)


def store_data(data, filename="amazon_global_dataset_by_keyword.json"):
    if data:
        with open(filename, "w") as file:
            json.dump(data, file, indent=4)
        print(f"Data saved in {filename}.")
    else:
        print("No data to store.")


if __name__ == "__main__":
    API_TOKEN = "YOUR_API_TOKEN"
    DATASET_ID = "gd_lwhideng15g8jg63s7"

    # Define the dataset with keywords, domain, and pages_to_search
    datasets = [
        {
            "keywords": "Mitutoyo",
            "domain": "https://www.amazon.com",
            "pages_to_search": 1,
        },
        {
            "keywords": "smart watch",
            "domain": "https://www.amazon.co.uk",
            "pages_to_search": 2,
        },
        {
            "keywords": "football",
            "domain": "https://www.amazon.in",
            "pages_to_search": 4,
        },
        {
            "keywords": "baby cloth",
            "domain": "https://www.amazon.de",
            "pages_to_search": 3,
        },
    ]

    # Trigger dataset collection
    snapshot_id = trigger_datasets(API_TOKEN, DATASET_ID, datasets)

    if snapshot_id:
        # Retrieve the data once the snapshot is ready
        data = get_snapshot_data(API_TOKEN, snapshot_id)
        if data:
            store_data(data)
```
ì „ì²´ ì¶œë ¥ì€ [ì´ ìƒ˜í”Œ JSON íŒŒì¼](https://github.com/bright-kr/Amazon-scraper/blob/main/output_data/amazon_global_dataset_by_keyword.json)ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.